{"cells":[{"cell_type":"markdown","metadata":{"id":"UNW6_2liiKTu"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31075,"status":"ok","timestamp":1693661922513,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"ywMmRNOjhpxW","outputId":"0a7602ee-06ef-4f71-b212-eab7fcf9a660"},"outputs":[],"source":["#!pip install pyLDAvis\n","#!pip install visdom\n","import pandas as pd\n","import nltk\n","import re\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.models import Phrases\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm\n","import pyLDAvis.gensim_models as gensimvis\n","import pyLDAvis\n","from sklearn.feature_extraction.text import CountVectorizer\n","tqdm.pandas()"]},{"cell_type":"markdown","metadata":{"id":"lx6nnLksiZ4w"},"source":["# Data"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88183,"status":"ok","timestamp":1693662112072,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"gRoevEtribNC","outputId":"804becd7-62b3-4bbe-9266-9e2e1a6c8d6a"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","df_lda_kickstarter = pd.read_csv('../kickstarter_cleaned.csv')"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"pLhiCzo6mEBI"},"source":["# Functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BkUOGlUsmEBN"},"outputs":[],"source":["def preprocess_text(document: str, stemmer: nltk.stem.WordNetLemmatizer, en_stop: set) -> list:\n","    \"\"\"Preprocesses a document to remove special characters/whitespace/etc\n","\n","    Args:\n","        document (str):\n","        stemmer (nltk.stem.WordNetLemmatizer): Stemmer from NLTK\n","        en_stop (set): Set of stop words, usually from NLTK\n","\n","    Returns:\n","        str: preprocessed document\n","    \"\"\"\n","\n","    # Remove all the special characters\n","    document = re.sub(r'\\W', ' ', document)\n","\n","    # remove all single characters\n","    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","\n","    # Remove single characters from the start\n","    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n","\n","    # Substituting multiple spaces with single space\n","    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","\n","    # Removing prefixed 'b'\n","    document = re.sub(r'^b\\s+', '', document)\n","\n","    # Converting to Lowercase\n","    document = document.lower()\n","\n","    # Tokenization\n","    tokens = nltk.word_tokenize(document)\n","\n","    # POS-Tagging\n","    tagged_tokens = nltk.pos_tag(tokens)\n","\n","    # Filter Nouns and Lemmatization\n","    lemmatized_nouns = []\n","    for token, pos in tagged_tokens:\n","        if pos.startswith('N'):  # Check if the token is a noun\n","            lemma = stemmer.lemmatize(token)\n","            # FIlter stop words, words that contain only numbers and short words\n","            if lemma not in en_stop and not lemma.isdigit() and len(lemma) > 2:\n","                lemmatized_nouns.append(lemma)\n","\n","    return lemmatized_nouns;"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-zvvGvaMmEBN"},"outputs":[],"source":["def preprocess_text_helper(t):\n","    stemmer = nltk.stem.WordNetLemmatizer()\n","    return preprocess_text(t, stemmer, stopwords.words('english'))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Create function to calculate topic distribution\n","def get_topic_distribution(text, dictionary, model):\n","    bow = dictionary.doc2bow(text)\n","    topic_probs = model.get_document_topics(bow)\n","    return topic_probs"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Create a function to extract the top n descriptions corresponding to a topic\n","def get_top_descriptions(model, df, corpus, chosen_topic, n):\n","\n","    print(model.show_topic(chosen_topic, topn=10))\n","\n","    # Get the document-topic distribution\n","    document_topic_distribution = model.get_document_topics(corpus)\n","\n","    # Ensure chosen_topic is within the valid range\n","    if 0 <= chosen_topic < model.num_topics:\n","        # Sort documents by their probability score for the chosen topic\n","        sorted_documents = sorted(\n","            enumerate(document_topic_distribution),\n","            key=lambda x: next((prob for topic, prob in x[1] if topic == chosen_topic), 0),\n","            reverse=True\n","        )\n","        top_n = 5  # Number of top documents to print\n","        for i, (doc_id, topic_probs) in enumerate(sorted_documents[:top_n]):\n","            document = corpus[doc_id]\n","            project_description = df.iloc[doc_id]['project_description']\n","            processed_description = df.iloc[doc_id]['processed_description']\n","            print(f\"Document {i + 1} (Corpus ID {doc_id}):\")\n","            print(\"Topic Probability:\", next((prob for topic, prob in topic_probs if topic == chosen_topic), 0))\n","            words = [word for word, freq in document]\n","            print(\"Document Text:\", words)\n","            print(\"Project Description:\", project_description)\n","            print(\"processed Description:\", processed_description)\n","            print(\"\\n\")\n","    else:\n","        print(f\"Chosen topic index {chosen_topic} is out of range.\")"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"mUcaUhplmEBV"},"source":["# LDA"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1693661922517,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"W0h8S88gmEBb"},"outputs":[],"source":["# Remove the columns\n","df_lda_kickstarter.drop(df_lda_kickstarter.columns.difference(['project_description', 'project_category_id', 'project_parent_category_id', 'project_state']), axis=1,inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"xOZ9oyXumtzl"},"source":["### Technology Category"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1693661922517,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"-gpcuFupl7RT"},"outputs":[],"source":["df_lda_kickstarter_technology = df_lda_kickstarter.copy()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"iUu8VqLYyOUQ"},"outputs":[],"source":["# Filter Dataframe by Technology category (number 16)\n","df_lda_kickstarter_technology = df_lda_kickstarter_technology[(df_lda_kickstarter_technology['project_category_id'] == 16) | (df_lda_kickstarter_technology['project_parent_category_id'] == 16)]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Z67x9LJ2-VWd"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\CoolerMaster\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\CoolerMaster\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\CoolerMaster\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d465dcfd9144a93a7497a54e78c7115","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25653 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Preprocessing general steps\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","df_lda_kickstarter_technology['processed_description'] = df_lda_kickstarter_technology['project_description'].progress_apply(preprocess_text_helper)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Qf3CHYh2E8lB"},"outputs":[],"source":["data_technology = df_lda_kickstarter_technology['processed_description'].tolist()\n","# Compute n-grams\n","from gensim.models import Phrases\n","\n","# Add n-grams to docs (only ones that appear 20 times or more).\n","ngrams_technology = Phrases(data_technology, min_count=20)\n","\n","for idx in range(len(data_technology)):\n","    for token in ngrams_technology[data_technology[idx]]:\n","        if '_' in token:\n","            # Token is a n-grams, add to document.\n","            data_technology[idx].append(token)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"PUeg8iOxmEBc"},"outputs":[],"source":["# create dictionary\n","dictionary_technology = corpora.Dictionary(data_technology)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"dtciKE_2-AlX"},"outputs":[],"source":["# Filter out words that occur less than 5 documents, or more than 50% of the documents.\n","dictionary_technology.filter_extremes(no_below=5, no_above=0.5)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"iyq6wzLCCWlr"},"outputs":[],"source":["# Define your custom stoplist\n","custom_stoplist_technology = [\"project\", \"kickstarter\", \"pledge\", \"backer\", \"campaign\", \"goal\", \"product\", \"kickstarter_campaign\", \"funding_goal\", \"reward\", \"stretch\", \"stretch_goal\", \"fund\", \"funding\", \"pledge_level\",\n","                            \"tier\", \"reward_tier\", \"pledge_amount\",\n","                            \"play\", \"replay\", \"browser\", \"html5\", \"play_replay\", \"html5_browser\", \n","                            \"people\", \"world\", \"thing\", \"lot\", \"device\", \"system\", \"user\", \"way\", \"technology\", \"use\", \"design\", \"year\", \"month\", \"day\", \"hour\", \"www\", \"com\", \"one\"\n","                            \"information\", \"opportunity\", \"fund\", \"funding\", \"technology\", \"solution\", \"developement\", \"tech\", \"experience\", \"level\", \"support\", \"stretch\", \"stretch_goal\", \"let\", \"detail\",\n","                            \"option\", \"please\", \"help\", \"life\", \"idea\", \"share\", \"everything\", \"thank\", \"quality\", \"version\"]\n","# Add your custom stop words to the dictionary\n","stop_ids_technology = [dictionary_technology.token2id[word] for word in custom_stoplist_technology if word in dictionary_technology.token2id]\n","# Remove the stop words from the dictionary\n","dictionary_technology.filter_tokens(bad_ids=stop_ids_technology)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"sF-kLHTIBCfA"},"outputs":[],"source":["# create corpus\n","corpus_technology = [dictionary_technology.doc2bow(tokens) for tokens in data_technology]"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5563,"status":"ok","timestamp":1686749736312,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"Esxs4nY6o3qb","outputId":"51f4045c-c31a-45bf-926a-10fda438b28d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('app', 35322), ('power', 19311), ('video', 17889), ('phone', 17790), ('feature', 15033), ('part', 15025), ('team', 14904), ('business', 14458), ('development', 14429), ('battery', 13692), ('software', 13581), ('home', 13580), ('data', 13508), ('application', 12942), ('prototype', 12919), ('community', 12682), ('work', 12404), ('service', 12134), ('cost', 12047), ('company', 11999), ('platform', 11886), ('production', 11741), ('information', 11277), ('board', 10995), ('student', 10781), ('tool', 10613), ('friend', 10443), ('game', 10051), ('order', 10042), ('water', 10029), ('market', 9947), ('money', 9893), ('hand', 9853), ('access', 9654), ('light', 9309), ('control', 9257), ('case', 9192), ('computer', 9152), ('color', 9131), ('process', 9073), ('need', 9073), ('problem', 8656), ('place', 8630), ('everyone', 8574), ('medium', 8550), ('music', 8547), ('family', 8519), ('sensor', 8286), ('child', 8258), ('event', 8189), ('material', 7918), ('website', 7917), ('camera', 7880), ('space', 7750), ('program', 7712), ('source', 7534), ('school', 7521), ('site', 7462), ('something', 7379), ('model', 7283), ('car', 7258), ('kit', 6951), ('customer', 6766), ('size', 6681), ('number', 6592), ('network', 6554), ('area', 6490), ('step', 6452), ('unit', 6422), ('location', 6401), ('course', 6386), ('button', 6349), ('end', 6259), ('page', 6235), ('component', 6206), ('image', 6192), ('price', 6182), ('type', 6180), ('energy', 6017), ('hardware', 5955), ('industry', 5917), ('cable', 5883), ('state', 5845), ('store', 5842), ('point', 5840), ('ability', 5837), ('plan', 5828), ('group', 5827), ('kid', 5791), ('card', 5765), ('air', 5737), ('member', 5691), ('today', 5654), ('others', 5637), ('photo', 5563), ('code', 5543), ('example', 5539), ('machine', 5495), ('line', 5471), ('research', 5313)]\n"]}],"source":["from collections import Counter\n","\n","# Count word occurrences\n","word_counts_technology = Counter()\n","for doc in corpus_technology:\n","    for word_id, count in doc:\n","        word = dictionary_technology[word_id]\n","        word_counts_technology[word] += count\n","\n","# Get most frequent words\n","most_common_technology = word_counts_technology.most_common(100)\n","print(most_common_technology)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1686749736313,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"t42CpBmVBeLu","outputId":"326d0136-ee7d-44c4-a746-f134d508bd56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique tokens: 17583\n","Number of documents: 25653\n"]}],"source":["print('Number of unique tokens: %d' % len(dictionary_technology))\n","print('Number of documents: %d' % len(corpus_technology))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n","\n","# define perplexity callback\n","pl = PerplexityMetric(corpus=corpus_technology, logger=\"visdom\", title=\"Perplexity\")\n","\n","# define other remaining metrics available\n","ch_umass = CoherenceMetric(corpus=corpus_technology, coherence=\"u_mass\", logger=\"visdom\", title=\"Coherence (u_mass)\")\n","ch_cv = CoherenceMetric(corpus=corpus_technology, texts=data_technology, coherence=\"c_v\", logger=\"visdom\", title=\"Coherence (c_v)\")\n","diff_kl = DiffMetric(distance=\"kullback_leibler\", logger=\"visdom\", title=\"Diff (kullback_leibler)\")\n","convergence_kl = ConvergenceMetric(distance=\"jaccard\", logger=\"visdom\", title=\"Convergence (jaccard)\")\n","\n","callbacks = [pl, ch_umass, ch_cv, diff_kl, convergence_kl]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"vy75OBJFJ6BY"},"outputs":[],"source":["lda_model_technology = gensim.models.LdaModel(corpus=corpus_technology, id2word=dictionary_technology, num_topics=100, passes=15, per_word_topics=True, chunksize=1500, iterations=150, alpha='auto') #callbacks=callbacks"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["lda_model_technology.save('../LDA/technology/100/LDA_technology_100_final')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\anaconda3\\envs\\Bachelorthesis\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n","  default_term_info = default_term_info.sort_values(\n"]}],"source":["vis = gensimvis.prepare(lda_model_technology, corpus_technology, dictionary_technology)\n","pyLDAvis.save_html(vis, '../LDA/technology/vis/100_final.html')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_top_descriptions(lda_model_technology, df_lda_kickstarter_technology, corpus_technology, 21, 10)"]},{"cell_type":"markdown","metadata":{"id":"3ih5dfcLdwhc"},"source":["### Games Category"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"rbu_Gjn4d2_C"},"outputs":[],"source":["df_lda_kickstarter_games = df_lda_kickstarter.copy()"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Lnj8yfuAsbYm"},"outputs":[],"source":["# Filter Dataframe by Games category (number 12)\n","df_lda_kickstarter_games = df_lda_kickstarter_games[(df_lda_kickstarter_games['project_category_id'] == 12) | (df_lda_kickstarter_games['project_parent_category_id'] == 12)]"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"qmEJrLO9sds7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6aedddd705f473db34e38191b0e0ca6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/35790 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Preprocessing\n","df_lda_kickstarter_games['project_description'] = df_lda_kickstarter_games['project_description'].progress_apply(preprocess_text_helper)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"V1WNGUAz1Mpq"},"outputs":[],"source":["data_games = df_lda_kickstarter_games['project_description'].tolist()\n","# Compute bigrams/trigrams\n","from gensim.models import Phrases\n","\n","# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n","ngrams_games = Phrases(data_games, min_count=20)\n","for idx in range(len(data_games)):\n","    for token in ngrams_games[data_games[idx]]:\n","        if '_' in token:\n","            # Token is a bigram/trigram, add to document.\n","            data_games[idx].append(token)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"pkQa293qX4OC"},"outputs":[],"source":["# create dictionary\n","dictionary_games = corpora.Dictionary(data_games)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"010Cld_k1ddq"},"outputs":[],"source":["# Filter out words that occur less than 5 documents, or more than 50% of the documents.\n","dictionary_games.filter_extremes(no_below=5, no_above=0.5)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"XCGoyN7I1d7C"},"outputs":[],"source":["# Define your custom stoplist\n","custom_stoplist_games = [\"project\", \"kickstarter\", \"pledge\", \"backer\", \"campaign\", \"goal\", \"product\", \"kickstarter_campaign\", \"funding_goal\", \"reward\", \"stretch\", \"stretch_goal\", \"fund\", \"funding\", \"pledge_level\",\n","                        \"tier\", \"reward_tier\", \"pledge_amount\",\n","                        \"play\", \"replay\", \"browser\", \"html5\", \"play_replay\", \"html5_browser\",\n","                        \"year\", \"month\", \"day\", \"hour\",\n","                        \"people\", \"thing\", \"lot\", \"let\", \"something\", \"anyone\", \"card\", \"help\", \"one\", \"thing\", \"character\", \"video\", \"level\", \"design\", \"use\",\n","                        \"system\", \"feature\", \"play\", \"style\", \"title\", \"feedback\", \"support\", \"version\", \"please\", \"www\", \"com\", \"life\", \"way\", \"world\", \"idea\", \"share\", \"everything\", \"thank\", \"quality\", \"version\"]                       \n","# Add your custom stop words to the dictionary\n","stop_ids_games = [dictionary_games.token2id[word] for word in custom_stoplist_games if word in dictionary_games.token2id]\n","# Remove the stop words from the dictionary\n","dictionary_games.filter_tokens(bad_ids=stop_ids_games)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"rbbQ1kfd1g9H"},"outputs":[],"source":["# create corpus\n","corpus_games = [dictionary_games.doc2bow(tokens) for tokens in data_games]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"SwxR2mZ6xuq7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('deck', 51270), ('book', 30165), ('dice', 29503), ('art', 29073), ('board', 25934), ('rule', 24708), ('story', 24141), ('box', 23815), ('copy', 23200), ('shipping', 22741), ('team', 22395), ('adventure', 22082), ('friend', 21723), ('set', 21591), ('cost', 20616), ('order', 20413), ('point', 20404), ('edition', 19916), ('item', 19505), ('hand', 19351), ('color', 19134), ('experience', 18563), ('work', 17718), ('part', 17517), ('page', 17139), ('action', 16457), ('fun', 16303), ('number', 15853), ('monster', 15520), ('power', 15290), ('everyone', 15282), ('print', 15147), ('piece', 15054), ('battle', 14921), ('ability', 14715), ('artist', 14209), ('map', 14118), ('development', 14014), ('money', 13944), ('option', 13186), ('expansion', 13156), ('place', 13135), ('family', 12912), ('end', 12906), ('name', 12869), ('hero', 12617), ('space', 12525), ('city', 12448), ('turn', 12390), ('community', 12026), ('custom', 12001), ('pack', 11588), ('production', 11576), ('event', 11535), ('company', 11494), ('amount', 11370), ('miniature', 11120), ('group', 11100), ('dungeon', 10927), ('war', 10769), ('designer', 10650), ('party', 10559), ('weapon', 10528), ('enemy', 10414), ('image', 10406), ('word', 10256), ('skill', 10185), ('base', 10044), ('side', 10029), ('artwork', 9965), ('table', 9849), ('content', 9836), ('type', 9777), ('example', 9687), ('gameplay', 9670), ('choice', 9515), ('price', 9391), ('role', 9379), ('model', 9323), ('question', 9203), ('detail', 9138), ('playing', 9103), ('music', 9018), ('pdf', 8857), ('add', 8845), ('dragon', 8818), ('round', 8749), ('combat', 8686), ('area', 8664), ('size', 8605), ('core', 8602), ('line', 8521), ('class', 8511), ('strategy', 8506), ('creature', 8393), ('series', 8387), ('location', 8356), ('puzzle', 8340), ('ons', 8238), ('store', 8191)]\n"]}],"source":["from collections import Counter\n","\n","# Count word occurrences\n","word_counts_games = Counter()\n","for doc in corpus_games:\n","    for word_id, count in doc:\n","        word = dictionary_games[word_id]\n","        word_counts_games[word] += count\n","\n","# Get most frequent words\n","most_common_games = word_counts_games.most_common(100)\n","print(most_common_games)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1686750154115,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"ReG56hlI8sbj","outputId":"ed057706-cddd-471c-c0cf-12ee4e9287fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique tokens: 25819\n","Number of documents: 35790\n"]}],"source":["print('Number of unique tokens: %d' % len(dictionary_games))\n","print('Number of documents: %d' % len(corpus_games))"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n","\n","# define perplexity callback\n","pl = PerplexityMetric(corpus=corpus_games, logger=\"visdom\", title=\"Perplexity\")\n","\n","# define other remaining metrics available\n","ch_umass = CoherenceMetric(corpus=corpus_games, coherence=\"u_mass\", logger=\"visdom\", title=\"Coherence (u_mass)\")\n","ch_cv = CoherenceMetric(corpus=corpus_games, texts=data_games, coherence=\"c_v\", logger=\"visdom\", title=\"Coherence (c_v)\")\n","diff_kl = DiffMetric(distance=\"kullback_leibler\", logger=\"visdom\", title=\"Diff (kullback_leibler)\")\n","convergence_kl = ConvergenceMetric(distance=\"jaccard\", logger=\"visdom\", title=\"Convergence (jaccard)\")\n","\n","callbacks = [pl, ch_umass, ch_cv, diff_kl, convergence_kl]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["lda_model_games = gensim.models.LdaModel(corpus=corpus_games, id2word=dictionary_games, num_topics=70, passes=15, per_word_topics=True, chunksize=2000, iterations=150, alpha='auto')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["lda_model_games.save('../LDA/games/70/LDA_games_70_final')"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\anaconda3\\envs\\Bachelorthesis\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n","  default_term_info = default_term_info.sort_values(\n"]}],"source":["vis = gensimvis.prepare(lda_model_games, corpus_games, dictionary_games)\n","pyLDAvis.save_html(vis, '../LDA/games/vis/70_final.html')"]},{"cell_type":"markdown","metadata":{"id":"z2kFHx1e5QDS"},"source":["### Design Category"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"7gAw4I_P7HwW"},"outputs":[],"source":["df_lda_kickstarter_design = df_lda_kickstarter.copy()"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"ogi251Qd7Hwk"},"outputs":[],"source":["# Filter Dataframe by Design category (number 7)\n","df_lda_kickstarter_design = df_lda_kickstarter_design[(df_lda_kickstarter_design['project_category_id'] == 7) | (df_lda_kickstarter_design['project_parent_category_id'] == 7)]"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"X5m_Oul17Hwl"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\CoolerMaster\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\CoolerMaster\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81c9a622ae1d4d40b070782b2ef2481b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/27356 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Preprocessing general steps\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","df_lda_kickstarter_design['project_description'] = df_lda_kickstarter_design['project_description'].progress_apply(preprocess_text_helper)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"EqFabi7p7Hwm"},"outputs":[],"source":["data_design = df_lda_kickstarter_design['project_description'].tolist()\n","# Compute n-grams\n","from gensim.models import Phrases\n","\n","# Add n-grams to docs (only ones that appear 20 times or more).\n","ngrams_design = Phrases(data_design, min_count=20)\n","for idx in range(len(data_design)):\n","    for token in ngrams_design[data_design[idx]]:\n","        if '_' in token:\n","            # Token is a n-grams, add to document.\n","            data_design[idx].append(token)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"WvWVbiXr7Hwn"},"outputs":[],"source":["# create dictionary\n","dictionary_design = corpora.Dictionary(data_design)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"LIa4iNif7Hwn"},"outputs":[],"source":["# Filter out words that occur less than 5 documents, or more than 50% of the documents.\n","dictionary_design.filter_extremes(no_below=5, no_above=0.5)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"wri17dHo7Hwo"},"outputs":[],"source":["# Define your custom stoplist\n","custom_stoplist_design = [\"project\", \"kickstarter\", \"pledge\", \"backer\", \"campaign\", \"goal\", \"product\", \"kickstarter_campaign\", \"funding_goal\", \"reward\", \"stretch\", \"stretch_goal\", \"fund\", \"funding\", \"pledge_level\",\n","                        \"tier\", \"reward_tier\", \"pledge_amount\",\n","                        \"play\", \"replay\", \"browser\", \"html5\", \"play_replay\", \"html5_browser\",\n","                        \"year\", \"month\", \"day\", \"hour\",\n","                        \"people\", \"life\", \"way\", \"world\", \"idea\", \"share\", \"everything\", \"thank\", \"quality\", \"version\", \"thing\", \"lot\", \"let\", \"something\", \"anyone\", \"card\", \"help\", \"one\", \n","                        \"thing\", \"character\", \"video\", \"level\", \"design\", \"use\", \"system\", \"feature\", \"play\", \"style\", \"title\", \"feedback\", \"support\", \"version\", \"please\", \"www\", \"com\"]\n","# Add your custom stop words to the dictionary\n","stop_ids_design = [dictionary_design.token2id[word] for word in custom_stoplist_design if word in dictionary_design.token2id]\n","# Remove the stop words from the dictionary\n","dictionary_design.filter_tokens(bad_ids=stop_ids_design)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"qPAAP6_I7Hwo"},"outputs":[],"source":["# create corpus\n","corpus_design = [dictionary_design.doc2bow(tokens) for tokens in data_design]"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6765,"status":"ok","timestamp":1686750696337,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"OAnSwH0M7Hwo","outputId":"26a7349b-2660-445e-a802-91157a7dd82b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('production', 23017), ('color', 22842), ('material', 21412), ('hand', 20498), ('prototype', 18012), ('bag', 17607), ('case', 16266), ('order', 15837), ('size', 15638), ('part', 15272), ('water', 15033), ('work', 13376), ('home', 12581), ('process', 12509), ('tool', 12506), ('cost', 11615), ('pocket', 11440), ('company', 11289), ('phone', 11129), ('friend', 10742), ('piece', 10544), ('place', 10535), ('option', 10520), ('experience', 10493), ('space', 10281), ('steel', 9811), ('market', 9763), ('business', 9712), ('wallet', 9606), ('team', 9534), ('device', 9348), ('family', 9285), ('line', 9028), ('shipping', 8790), ('side', 8739), ('box', 8713), ('watch', 8697), ('bottle', 8558), ('child', 8368), ('model', 8134), ('end', 8120), ('everyone', 8039), ('item', 8037), ('power', 7976), ('community', 7944), ('problem', 7926), ('need', 7921), ('body', 7918), ('art', 7628), ('manufacturing', 7575), ('price', 7525), ('custom', 7490), ('money', 7420), ('strap', 7216), ('plastic', 7177), ('board', 7141), ('solution', 7097), ('wood', 7094), ('light', 6982), ('kid', 6795), ('pack', 6591), ('car', 6571), ('inch', 6556), ('surface', 6443), ('technology', 6410), ('designer', 6398), ('paper', 6396), ('development', 6304), ('name', 6275), ('thanks', 6266), ('page', 6262), ('iphone', 6261), ('manufacturer', 6259), ('set', 6258), ('pin', 6150), ('aluminum', 6134), ('brand', 6089), ('patent', 6081), ('bike', 6073), ('step', 6055), ('type', 6000), ('glass', 5981), ('book', 5977), ('choice', 5933), ('detail', 5921), ('leather', 5868), ('story', 5866), ('food', 5854), ('weight', 5821), ('shirt', 5804), ('dog', 5776), ('image', 5768), ('point', 5758), ('kit', 5698), ('shape', 5616), ('amount', 5611), ('week', 5589), ('look', 5518), ('machine', 5456), ('battery', 5435)]\n"]}],"source":["from collections import Counter\n","\n","# Count word occurrences\n","word_counts_design = Counter()\n","for doc in corpus_design:\n","    for word_id, count in doc:\n","        word = dictionary_design[word_id]\n","        word_counts_design[word] += count\n","\n","# Get most frequent words\n","most_common_design = word_counts_design.most_common(100)\n","print(most_common_design)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1686750696338,"user":{"displayName":"Hanschyo","userId":"06836591315332070494"},"user_tz":-120},"id":"nkeAqDhp7Hwp","outputId":"fe32503b-9642-40d7-da20-22d8fa977846"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique tokens: 19990\n","Number of documents: 27356\n"]}],"source":["print('Number of unique tokens: %d' % len(dictionary_design))\n","print('Number of documents: %d' % len(corpus_design))"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n","\n","# define perplexity callback\n","pl = PerplexityMetric(corpus=corpus_design, logger=\"visdom\", title=\"Perplexity\")\n","\n","# define other remaining metrics available\n","ch_umass = CoherenceMetric(corpus=corpus_design, coherence=\"u_mass\", logger=\"visdom\", title=\"Coherence (u_mass)\")\n","ch_cv = CoherenceMetric(corpus=corpus_design, texts=data_design, coherence=\"c_v\", logger=\"visdom\", title=\"Coherence (c_v)\")\n","diff_kl = DiffMetric(distance=\"kullback_leibler\", logger=\"visdom\", title=\"Diff (kullback_leibler)\")\n","convergence_kl = ConvergenceMetric(distance=\"jaccard\", logger=\"visdom\", title=\"Convergence (jaccard)\")\n","\n","callbacks = [pl, ch_umass, ch_cv, diff_kl, convergence_kl]"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["lda_model_design = gensim.models.LdaModel(corpus=corpus_design, id2word=dictionary_design, num_topics=100, passes=15, per_word_topics=True, chunksize=1500, iterations=150, alpha='auto')"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["lda_model_design.save('../LDA/design/100/LDA_design_100_final')"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\anaconda3\\envs\\Bachelorthesis\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n","  default_term_info = default_term_info.sort_values(\n"]}],"source":["vis = gensimvis.prepare(lda_model_design, corpus_design, dictionary_design)\n","pyLDAvis.save_html(vis, '../LDA/design/vis/100_final.html')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPm1uRw+MpIU9iuzSTGl6Zy","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
